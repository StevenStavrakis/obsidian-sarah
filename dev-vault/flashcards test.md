Goal-oriented decisions are made on the assessment of expected reward or the value of an action

What is an action-outcome decision?
When an action is made based on the evaluation of expected outcomes

If you think there will be a positive outcome as a result of an action, then you will do that action to acquire the outcome. What is this an example of?
An action-outcome decision

What is a stimulus-response decision?
A response is made based on the presence of a stimulus

The ability of an outcome to reinforce a behavior depends on that outcome's value

What are the components of value?
- Magnitude/payoff
- Probability
- Effort/cost

What is "delay discounting"?
When the same reward magnitude has a lower value at longer delays

You choose to take five hundred dollar tomorrow as opposed to eight hundred dollars next week. What is this an example of?
Delay discounting

What did Hare et al. study (broadly)?
How value and control interact

Who are the participant in Hare et al.?
Self-reported dieters

What did self-reported dieters do during the rating phase in Hare et al?
Rated 50 different food items for taste and health on a five point scale

What did self-reported dieters do during the decision phase in Hare et al?
They chose between different foods

What are the independent variables in Hare et al?
1. Goal values (taste, health)
2. Whether participants were self-controllers or non-self-controllers (based on their choices)

What is the "reference item" in Hare et al?
It is a participant specific item determined during the rating phase. An item that the participant has indicated as neutral for both taste and health

How was a participant identified as a self-controller?
If the participant reliably chose the reference item over an unhealthy, tasty item, they were considered a self-controller

How was a participant identified as a non-self-controller?
If they reliably chose an unhealthy, tasty item over the reference item

Is there a brain region that is sensitive to value?
Yes. The Orbitofrontal Cortex OFC

What evidence is there that the OFC is sensitive to value?
Hare et al. showed that OFC activity was higher for foods that were ranked higher in taste preference

OFC activity does change as a function of taste preference. There is a positive, linear relationship between the self-reported tastiness of a food and OFC activity

Does the value sensitivity to taste vs. health differ between self-controllers and non-self-controllers?
Yes. While OFC sensitivity is similar for high taste rating between both groups, non-self-controllers have dramatically lower OFC activity when presented high health items compared to self-controllers

In non-self-controllers, OFC activity doesn't seem to scale with health rating at all.

The more healthy something is, the more the OFC is active ONLY for self-controllers

Is there a control-sensitive region with greater activity when control is exerted?
Yes. LPFC activity is greater when participants exert self-control and chose the reference item over the tasty item for both self-controllers and non-self-controllers

How does LPFC activity differ between self-controllers and non-self-controllers in trials where the unhealthy item was chosen over the reference item?
Self-controllers showed effectively no OFC activity during failed trials, while non-self-controllers showed relatively significant OFC activity

How does LPFC activity differ between self-controllers and non-self-controllers in trials where the healthy item was chosen over the reference item (successful trial)?
Self-controllers have a higher level of OFC activation than non-self-controllers in successful trials

How is value represented in the brain?
Orbitofrontal cortex (OFC) represents value and its representation may differ depending on control

What is the Rescorla-Wagner Model?
V<sub>t</sub> = (a * (L<sub>t</sub> - V<sub>t-1</sub>)) + V<sub>t-1</sub>

V<sub>t</sub>
Value on trial t

a
Learning rate (a constant)

L<sub>t</sub>
Reward obtained on trial t

V<sub>t-1</sub>
Value on trial t-1

In the Rescorla-Wagner model, what is value based on?
What happened (L<sub>t</sub>) compared to what you expected (V<sub>t-1</sub>) scaled by how much you learn (a) from any given trial

If a = 0...
You learn nothing and nothing ever changes

If L<sub>t</sub> = V<sub>t-1</sub>...
You learn nothing, the outcome matched the expectation, so value doesn't change

In the Rescorla-Wagner model, what leads to large changes in value?
Large differences in expected outcome (V<sub>t-1</sub>) and actual outcome (L<sub>t</sub>)

Prediction error leads to...
changes in value

How do we learn about value?
Comparing expected to received outcomes; the Rescorla-Wagner model

Is there a signal in the brain that reflects prediction error?
Yes

What are the two primary dopamine centers?
- Substantia nigra (SN)
- Ventral tegmental area (VTA)

Where does the VTA project to?
The nucleus accumbens (NAcc)

The NAcc is part of the ventral striatum

What did Olds and Milner's research find?
When rats were provided a button that activated an electrode in their VTA, they would self-stimulate at the expense of food, sometimes stimulating until they die.

If dopamine is a reward signal, then...
- Any time a reward is present, dopamine should increase (not the case)
- Punishments shouldn't induce dopamine changes (not the case)

In the Schultz et al. study, prior to training, when did the monkey experience a spike in dopamine activation?
When they got the juice

In the Schultz et al study, after training, when did the monkey experience a spike in dopamine activation?
After the bell (CS) was rung

In the Schultz et al study, after training, what happened if the CS was present, but not followed by the juice?
A dip in dopamine activity was observed

How do we know that dopamine doesn't correspond with reward?
- When you expect a reward, there is an increase in dopamine, not when you get the reward itself
- When you expect a reward and don't get it, you see a decrease in dopamine

Does dopamine increase whenever someone gets a reward?
No. It increases when someone receives an *unexpected* reward, or in anticipation of a reward.

What are the four conditions in Zaghloul et al?
- Expected gains
- Expected losses
- Unexpected gains
- Unexpected losses

What is the dependent variable in Zaghloul et al?
Firing rate of substantia nigra (SN) neurons

If dopamine represents reward, what can we expect as the outcome for Zaghloul et al?
SN firing rate should change for conditions 1 and 3

If dopamine represents prediction errors, what can we expect as the outcome for Zaghloul et al?
SN firing rate should change for conditions 3 and 4

What were the results of the Zaghloul et al research for the expected outcomes?
Not much change from baseline firing rate

What were the results of the Zaghloul et al research for the unexpected outcomes?
Significant deviations from baseline firing rate. Unexpected loss caused a significant dip, while unexpected gain caused a significant jump

How does the work of Zaghloul et all show us that dopamine doesn't equal reward?
Dopamine neurons fire less following and unexpected punishment/loss, which means dopamine corresponds more to prediction error

What is the evidence for dopamine being a prediction error signal?
- Dopamine does not increase during expected gains/rewards (Schulz et al)
- Dopamine should change during unexpected losses (Zaghloul)

What is the task if Frank et al?
The Japanese character task, with an addition

What is the Japanese character task?
Participants are shown multiple sets of two Japanese characters. Half the characters represent high reward, half represent low reward. The objective is for the participant to identify and more frequently choose the high reward characters

What were the independent variables in the Frank et al human lesion study?
- Reward feedback (positive for choosing positive character, negative for negative character)
- Patient groups (3): on or off L-DOPA, age matched results

What was the hypothesis in Frank et al?
Nonmedicated PD patients can't learn from positive feedback, but can learn from negative feedback. Medicated PD patients can learn from positive feedback, but can't learn from negative feedback

What pathway does D1 activate?
The direct pathway

What pathway does D2 activate?
The indirect pathway

What is the purpose of the additional test phase on Frank et al's modified Japanese character task?
To disambiguate positive from negative feedback. If the subject learned from positive feedback, he would be able to choose a character with a value of 80 over a character with a value of 70. If he learned from negative feedback, he would be able to choose a character with a value of 30 over one with a value of 20

What were the results of Frank et al?
L-DOPA subjects were better at choosing A over C, but in line with controls at avoiding B, while patients who are L-DOPA deficient choose A with controls and avoid B better than controls

Which subject group showed enhanced "no-go" learning in Frank et al?
Unmedicated PD patients

Which group showed enhanced "go" learning in Frank et al?
L-DOPA PD patients

In Kravitz et al, what was found regarding stimulating the indirect pathway?
Stimulating the indirect, no-go pathway resulted in less frequent pressing of the no-go lever. Reinforce avoidance behavior.

In Kravitz et al, what was found regarding stimulating the direct pathway?
It lead to more frequent pressing of the lever. Reinforce the selection behavior.

What does dopamine activity represent or code?
Not reward/pleasure, but prediction error: the difference in expected and actual outcomes, both for rewards and punishment